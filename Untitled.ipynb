{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017048c-a885-4104-8613-ed6d16d70b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc4bbaa-50f0-47eb-909c-1ce2ea5285ec",
   "metadata": {},
   "source": [
    "\n",
    "**Grateful Dead Concert Metadata Scraper (1990 - Sampled 1500 Items)**\n",
    "------------------------------------------------------------------\n",
    "\n",
    "This script retrieves metadata about Grateful Dead concerts from the year \n",
    "1990 using the Internet Archive Scraping API. To keep the dataset manageable, \n",
    "it saves only the first 1500 results, even though the archive contains \n",
    "more items for that year. At the end, the script prints a short summary \n",
    "(earliest date, latest date, most downloaded show).\n",
    "\n",
    "Data Source:\n",
    "- Internet Archive, \"Grateful Dead Collection\"\n",
    "  URL: https://archive.org/details/GratefulDead\n",
    "\n",
    "API Documentation:\n",
    "- Internet Archive Search & Scraping API\n",
    "  https://archive.org/help/aboutsearch.htm\n",
    "\n",
    "Example Items (used for metadata reference):\n",
    "- Grateful Dead Live at Capital Centre on 1990-03-14\n",
    "  https://archive.org/details/gd1990-03-14.Nak300CP4.Fitzy.Keo.125852.Flac1644\n",
    "- Grateful Dead Live at Deer Creek Music Center on 1990-07-18\n",
    "  https://archive.org/details/gd1990-07-18.schoeps.miller.117361.flac16\n",
    "\n",
    "Credits:\n",
    "- Internet Archive for providing open and accessible concert recordings \n",
    "  and metadata through their API.\n",
    "- Code structure adapted from Archive.org API usage examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea8517f-cf31-4ba8-8b6f-967a78b37358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 100 items so far...\n",
      "Fetched 200 items so far...\n",
      "Fetched 300 items so far...\n",
      "Fetched 400 items so far...\n",
      "Fetched 500 items so far...\n",
      "Fetched 600 items so far...\n",
      "Fetched 700 items so far...\n",
      "Fetched 800 items so far...\n",
      "Fetched 900 items so far...\n",
      "Fetched 1000 items so far...\n",
      "Fetched 1100 items so far...\n",
      "Fetched 1200 items so far...\n",
      "Fetched 1300 items so far...\n",
      "Fetched 1400 items so far...\n",
      "Fetched 1500 items so far...\n",
      "\n",
      "âœ… Total items fetched (sampled): 1500\n",
      "\n",
      "ðŸ“Š Dataset Summary (1990 Sample)\n",
      "--------------------------------\n",
      "Total items analyzed: 1500\n",
      "Earliest archive public date: 2005-06-02\n",
      "Latest archive public date: 2025-06-18\n",
      "Most downloaded show: Grateful Dead Live at Capital Centre on 1990-03-15\n",
      "Downloads: 86742\n",
      "Identifier: gd1990-03-15.28293.sbeok.shnf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_metadata(limit=1500):\n",
    "    endpoint = \"https://archive.org/services/search/v1/scrape\"\n",
    "    # Query for GratefulDead collection, year 1990 only\n",
    "    q = 'collection:GratefulDead AND year:1990'\n",
    "    fields = [\n",
    "        \"identifier\", \n",
    "        \"title\", \n",
    "        \"description\", \n",
    "        \"creator\", \n",
    "        \"year\", \n",
    "        \"addeddate\",\n",
    "        \"collection\", \n",
    "        \"mediatype\", \n",
    "        \"item_size\", \n",
    "        \"subjects\", \n",
    "        \"publicdate\",\n",
    "        \"downloads\", \n",
    "        \"files\"\n",
    "    ]\n",
    "    params = {\n",
    "        \"q\": q,\n",
    "        \"fields\": \",\".join(fields),\n",
    "        \"count\": 100,\n",
    "    }\n",
    "\n",
    "    cursor = None\n",
    "    all_items = []\n",
    "\n",
    "    while len(all_items) < limit:\n",
    "        if cursor:\n",
    "            params[\"cursor\"] = cursor\n",
    "\n",
    "        response = requests.get(endpoint, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        items = data.get(\"items\", [])\n",
    "        all_items.extend(items)\n",
    "\n",
    "        cursor = data.get(\"cursor\")\n",
    "        print(f\"Fetched {len(all_items)} items so far...\")\n",
    "\n",
    "        if not cursor:\n",
    "            break\n",
    "\n",
    "        time.sleep(1)  # friendly rate limit\n",
    "\n",
    "    return all_items[:limit]\n",
    "\n",
    "def save_to_file(items, filename=\"grateful_dead_1990_sample.json\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(items, f, indent=2)\n",
    "\n",
    "def summarize(items):\n",
    "    # Extract dates & downloads\n",
    "    dates = []\n",
    "    most_downloaded = None\n",
    "    max_downloads = -1\n",
    "\n",
    "    for item in items:\n",
    "        # Handle publicdate for earliest/latest show\n",
    "        pubdate = item.get(\"publicdate\")\n",
    "        if pubdate:\n",
    "            try:\n",
    "                dates.append(datetime.fromisoformat(pubdate.replace(\"Z\", \"\")))\n",
    "            except ValueError:\n",
    "                pass  # skip malformed dates\n",
    "\n",
    "        # Handle downloads\n",
    "        downloads = item.get(\"downloads\", 0)\n",
    "        if downloads is not None and downloads > max_downloads:\n",
    "            max_downloads = downloads\n",
    "            most_downloaded = item\n",
    "\n",
    "    if dates:\n",
    "        earliest = min(dates).strftime(\"%Y-%m-%d\")\n",
    "        latest = max(dates).strftime(\"%Y-%m-%d\")\n",
    "    else:\n",
    "        earliest, latest = \"N/A\", \"N/A\"\n",
    "\n",
    "    print(\"\\nðŸ“Š Dataset Summary (1990 Sample)\")\n",
    "    print(\"--------------------------------\")\n",
    "    print(f\"Total items analyzed: {len(items)}\")\n",
    "    print(f\"Earliest archive public date: {earliest}\")\n",
    "    print(f\"Latest archive public date: {latest}\")\n",
    "    if most_downloaded:\n",
    "        print(f\"Most downloaded show: {most_downloaded.get('title', 'Unknown')}\")\n",
    "        print(f\"Downloads: {max_downloads}\")\n",
    "        print(f\"Identifier: {most_downloaded.get('identifier')}\")\n",
    "\n",
    "def main():\n",
    "    items = fetch_metadata(limit=1500)\n",
    "    print(f\"\\nâœ… Total items fetched (sampled): {len(items)}\")\n",
    "    save_to_file(items)\n",
    "    summarize(items)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae48dfc-d81c-41ce-a52b-15aa54253599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
